{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3de9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupytertracerviz import init_multigpus_repl, multigpus\n",
    "init_multigpus_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6110c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU 1] Rank 1: Output sum 1.752981185913086\n",
      "[GPU 2] Rank 2: Output sum 1.752981185913086\n",
      "[GPU 0] Rank 0: Output sum 1.752981185913086\n"
     ]
    }
   ],
   "source": [
    "%%multigpus\n",
    "\n",
    "model = torch.nn.Linear(10, 10).cuda(rank)\n",
    "\n",
    "x = torch.randn(10, 10).cuda(rank)\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Rank {rank}: Output sum {output.sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8068e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%multigpus\n",
    "\n",
    "from torch.distributed.tensor.parallel import parallelize_module, ColwiseParallel\n",
    "from torch.distributed.device_mesh import init_device_mesh\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        w1 = self.w1(x)\n",
    "\n",
    "model = FeedForward(8192, 8192)\n",
    "device_mesh = init_device_mesh('cuda', (3,))\n",
    "linears = {name: ColwiseParallel(use_local_output = False) \\\n",
    "           for name, submodule in model.named_modules() \\\n",
    "           if isinstance(submodule, nn.Linear)}\n",
    "model = parallelize_module(model, device_mesh, linears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8349ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU 0] DTensor(local_tensor=tensor([[-0.0091, -0.0020, -0.0044,  ...,  0.0051, -0.0003, -0.0052],\n",
      "        [-0.0031, -0.0035,  0.0102,  ...,  0.0049,  0.0089, -0.0098],\n",
      "        [-0.0023,  0.0038,  0.0077,  ...,  0.0042,  0.0058,  0.0008],\n",
      "        ...,\n",
      "        [ 0.0039, -0.0059,  0.0026,  ..., -0.0065,  0.0105,  0.0100],\n",
      "        [-0.0059,  0.0055,  0.0086,  ..., -0.0009, -0.0025,  0.0101],\n",
      "        [ 0.0110,  0.0024, -0.0085,  ...,  0.0073, -0.0097,  0.0062]],\n",
      "       device='cuda:0'), device_mesh=DeviceMesh('cuda', [0, 1, 2]), placements=(Shard(dim=0),))\n",
      "[GPU 1] DTensor(local_tensor=tensor([[ 0.0100, -0.0057, -0.0053,  ..., -0.0034, -0.0009,  0.0100],\n",
      "        [-0.0042,  0.0054, -0.0007,  ..., -0.0038,  0.0090, -0.0033],\n",
      "        [-0.0012, -0.0079, -0.0041,  ...,  0.0049,  0.0048,  0.0045],\n",
      "        ...,\n",
      "        [-0.0007, -0.0089, -0.0094,  ..., -0.0040,  0.0080, -0.0100],\n",
      "        [ 0.0039,  0.0050,  0.0066,  ..., -0.0005,  0.0077,  0.0065],\n",
      "        [ 0.0014, -0.0091,  0.0014,  ..., -0.0093,  0.0064, -0.0055]],\n",
      "       device='cuda:1'), device_mesh=DeviceMesh('cuda', [0, 1, 2]), placements=(Shard(dim=0),))\n",
      "[GPU 2] DTensor(local_tensor=tensor([[-0.0018,  0.0004,  0.0029,  ...,  0.0004,  0.0007, -0.0018],\n",
      "        [-0.0063, -0.0037, -0.0055,  ..., -0.0087, -0.0095, -0.0045],\n",
      "        [ 0.0079,  0.0056, -0.0037,  ..., -0.0092, -0.0034,  0.0067],\n",
      "        ...,\n",
      "        [ 0.0024,  0.0016,  0.0049,  ..., -0.0001, -0.0020,  0.0080],\n",
      "        [-0.0085,  0.0087, -0.0018,  ..., -0.0020, -0.0025, -0.0019],\n",
      "        [-0.0014, -0.0048, -0.0007,  ...,  0.0042,  0.0071,  0.0082]],\n",
      "       device='cuda:2'), device_mesh=DeviceMesh('cuda', [0, 1, 2]), placements=(Shard(dim=0),))\n"
     ]
    }
   ],
   "source": [
    "%%multigpus\n",
    "\n",
    "print(model.w1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3853187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU 0] {'training': True, '_parameters': {'weight': DTensor(local_tensor=tensor([[-0.0091, -0.0020, -0.0044,  ...,  0.0051, -0.0003, -0.0052],\n",
      "        [-0.0031, -0.0035,  0.0102,  ...,  0.0049,  0.0089, -0.0098],\n",
      "        [-0.0023,  0.0038,  0.0077,  ...,  0.0042,  0.0058,  0.0008],\n",
      "        ...,\n",
      "        [ 0.0039, -0.0059,  0.0026,  ..., -0.0065,  0.0105,  0.0100],\n",
      "        [-0.0059,  0.0055,  0.0086,  ..., -0.0009, -0.0025,  0.0101],\n",
      "        [ 0.0110,  0.0024, -0.0085,  ...,  0.0073, -0.0097,  0.0062]],\n",
      "       device='cuda:0'), device_mesh=DeviceMesh('cuda', [0, 1, 2]), placements=(Shard(dim=0),)), 'bias': None}, '_buffers': {}, '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict([(1, <function distribute_module.<locals>.<lambda> at 0x7f577d652ef0>)]), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict([(0, <function distribute_module.<locals>.<lambda> at 0x7f577d668c10>)]), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': {}, 'in_features': 8192, 'out_features': 8192}\n",
      "[GPU 2] {'training': True, '_parameters': {'weight': DTensor(local_tensor=tensor([[-0.0018,  0.0004,  0.0029,  ...,  0.0004,  0.0007, -0.0018],\n",
      "        [-0.0063, -0.0037, -0.0055,  ..., -0.0087, -0.0095, -0.0045],\n",
      "        [ 0.0079,  0.0056, -0.0037,  ..., -0.0092, -0.0034,  0.0067],\n",
      "        ...,\n",
      "        [ 0.0024,  0.0016,  0.0049,  ..., -0.0001, -0.0020,  0.0080],\n",
      "        [-0.0085,  0.0087, -0.0018,  ..., -0.0020, -0.0025, -0.0019],\n",
      "        [-0.0014, -0.0048, -0.0007,  ...,  0.0042,  0.0071,  0.0082]],\n",
      "       device='cuda:2'), device_mesh=DeviceMesh('cuda', [0, 1, 2]), placements=(Shard(dim=0),)), 'bias': None}, '_buffers': {}, '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict([(1, <function distribute_module.<locals>.<lambda> at 0x7f577d652ef0>)]), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict([(0, <function distribute_module.<locals>.<lambda> at 0x7f577d668c10>)]), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': {}, 'in_features': 8192, 'out_features': 8192}\n",
      "[GPU 1] {'training': True, '_parameters': {'weight': DTensor(local_tensor=tensor([[ 0.0100, -0.0057, -0.0053,  ..., -0.0034, -0.0009,  0.0100],\n",
      "        [-0.0042,  0.0054, -0.0007,  ..., -0.0038,  0.0090, -0.0033],\n",
      "        [-0.0012, -0.0079, -0.0041,  ...,  0.0049,  0.0048,  0.0045],\n",
      "        ...,\n",
      "        [-0.0007, -0.0089, -0.0094,  ..., -0.0040,  0.0080, -0.0100],\n",
      "        [ 0.0039,  0.0050,  0.0066,  ..., -0.0005,  0.0077,  0.0065],\n",
      "        [ 0.0014, -0.0091,  0.0014,  ..., -0.0093,  0.0064, -0.0055]],\n",
      "       device='cuda:1'), device_mesh=DeviceMesh('cuda', [0, 1, 2]), placements=(Shard(dim=0),)), 'bias': None}, '_buffers': {}, '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict([(1, <function distribute_module.<locals>.<lambda> at 0x7f577d652ef0>)]), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict([(0, <function distribute_module.<locals>.<lambda> at 0x7f577d668c10>)]), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': {}, 'in_features': 8192, 'out_features': 8192}\n"
     ]
    }
   ],
   "source": [
    "%%multigpus\n",
    "\n",
    "print(model.w1.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c267f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
